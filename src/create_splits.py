"""
CrÃ©ation des splits Train/Validation/Test pour GTZAN
Split stratifiÃ© : 70% train / 15% val / 15% test
"""

import os
import json
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.model_selection import train_test_split
import shutil

# Configuration
np.random.seed(42)  # ReproductibilitÃ©

DATA_PATH = Path("data/raw/Data/genres_original")
SPLITS_PATH = Path("data/splits")
SPLITS_PATH.mkdir(parents=True, exist_ok=True)

GENRES = ["blues", "classical", "country", "disco", "hiphop", 
          "jazz", "metal", "pop", "reggae", "rock"]

print("=" * 70)
print("ğŸ”€ CRÃ‰ATION DES SPLITS TRAIN/VAL/TEST")
print("=" * 70)

# ============================================================================
# 1. CHARGER LES MÃ‰TADONNÃ‰ES (exclure fichiers corrompus)
# ============================================================================
print("\nğŸ“‚ 1. Chargement des mÃ©tadonnÃ©es...")

# Charger les fichiers valides
df = pd.read_csv('data/processed/file_metadata.csv')
print(f"   â†’ {len(df)} fichiers valides chargÃ©s")

# Charger les fichiers corrompus (si existent)
corrupted_path = Path('data/processed/corrupted_files.csv')
if corrupted_path.exists():
    df_corrupted = pd.read_csv(corrupted_path)
    print(f"   âš ï¸  {len(df_corrupted)} fichiers corrompus exclus:")
    for _, row in df_corrupted.iterrows():
        print(f"      - {row['genre']}/{row['filename']}")
else:
    print("   âœ… Aucun fichier corrompu dÃ©tectÃ©")

# Statistiques par genre
print("\nğŸ“Š Distribution par genre:")
genre_counts = df['genre'].value_counts().sort_index()
for genre, count in genre_counts.items():
    print(f"   {genre:12s}: {count:3d} fichiers")

# ============================================================================
# 2. CRÃ‰ER LES SPLITS STRATIFIÃ‰S
# ============================================================================
print("\n" + "=" * 70)
print("âœ‚ï¸  2. CrÃ©ation des splits stratifiÃ©s (70/15/15)")
print("=" * 70)

# Ajouter le chemin complet
df['filepath'] = df.apply(lambda row: str(DATA_PATH / row['genre'] / row['filename']).replace('\\', '/'), axis=1)

# Split 1 : Train (70%) vs Temp (30%)
train_files, temp_files, train_labels, temp_labels = train_test_split(
    df['filepath'].values,
    df['genre'].values,
    test_size=0.30,
    stratify=df['genre'].values,
    random_state=42
)

# Split 2 : Temp â†’ Val (50%) + Test (50%) = 15% + 15% du total
val_files, test_files, val_labels, test_labels = train_test_split(
    temp_files,
    temp_labels,
    test_size=0.50,
    stratify=temp_labels,
    random_state=42
)

print(f"\nâœ… Splits crÃ©Ã©s:")
print(f"   ğŸ“š Train: {len(train_files):3d} fichiers ({len(train_files)/len(df)*100:.1f}%)")
print(f"   ğŸ“– Val:   {len(val_files):3d} fichiers ({len(val_files)/len(df)*100:.1f}%)")
print(f"   ğŸ“ Test:  {len(test_files):3d} fichiers ({len(test_files)/len(df)*100:.1f}%)")
print(f"   ğŸ¯ Total: {len(train_files)+len(val_files)+len(test_files):3d} fichiers")

# VÃ©rifier la stratification
print("\nğŸ­ VÃ©rification de la stratification par genre:")
print(f"\n{'Genre':<12} {'Train':<8} {'Val':<8} {'Test':<8} {'Total':<8}")
print("-" * 50)

for genre in GENRES:
    train_count = sum(train_labels == genre)
    val_count = sum(val_labels == genre)
    test_count = sum(test_labels == genre)
    total = train_count + val_count + test_count
    
    print(f"{genre:<12} {train_count:<8} {val_count:<8} {test_count:<8} {total:<8}")

# ============================================================================
# 3. SAUVEGARDER LES SPLITS
# ============================================================================
print("\n" + "=" * 70)
print("ğŸ’¾ 3. Sauvegarde des splits")
print("=" * 70)

# CrÃ©er DataFrames pour chaque split
train_df = pd.DataFrame({
    'filepath': train_files,
    'genre': train_labels,
    'filename': [Path(f).name for f in train_files]
})

val_df = pd.DataFrame({
    'filepath': val_files,
    'genre': val_labels,
    'filename': [Path(f).name for f in val_files]
})

test_df = pd.DataFrame({
    'filepath': test_files,
    'genre': test_labels,
    'filename': [Path(f).name for f in test_files]
})

# Sauvegarder en CSV
train_df.to_csv(SPLITS_PATH / 'train.csv', index=False)
val_df.to_csv(SPLITS_PATH / 'val.csv', index=False)
test_df.to_csv(SPLITS_PATH / 'test.csv', index=False)

print("âœ… Fichiers CSV sauvegardÃ©s:")
print(f"   - {SPLITS_PATH / 'train.csv'}")
print(f"   - {SPLITS_PATH / 'val.csv'}")
print(f"   - {SPLITS_PATH / 'test.csv'}")

# Sauvegarder aussi en JSON (pour faciliter le chargement)
splits_dict = {
    'train': train_files.tolist(),
    'val': val_files.tolist(),
    'test': test_files.tolist(),
    'label_mapping': {i: genre for i, genre in enumerate(GENRES)},
    'num_classes': len(GENRES)
}

with open(SPLITS_PATH / 'splits.json', 'w') as f:
    json.dump(splits_dict, f, indent=2)

print(f"âœ… Configuration JSON sauvegardÃ©e: {SPLITS_PATH / 'splits.json'}")

# ============================================================================
# 4. CRÃ‰ER UN RÃ‰SUMÃ‰ DÃ‰TAILLÃ‰
# ============================================================================
print("\n" + "=" * 70)
print("ğŸ“‹ 4. GÃ©nÃ©ration du rÃ©sumÃ©")
print("=" * 70)

summary = {
    'dataset': 'GTZAN Music Genre Classification',
    'total_files': len(df),
    'corrupted_files': len(pd.read_csv(corrupted_path)) if corrupted_path.exists() else 0,
    'genres': GENRES,
    'num_classes': len(GENRES),
    'splits': {
        'train': {
            'count': len(train_files),
            'percentage': round(len(train_files)/len(df)*100, 2),
            'distribution': {genre: int(sum(train_labels == genre)) for genre in GENRES}
        },
        'val': {
            'count': len(val_files),
            'percentage': round(len(val_files)/len(df)*100, 2),
            'distribution': {genre: int(sum(val_labels == genre)) for genre in GENRES}
        },
        'test': {
            'count': len(test_files),
            'percentage': round(len(test_files)/len(df)*100, 2),
            'distribution': {genre: int(sum(test_labels == genre)) for genre in GENRES}
        }
    },
    'random_seed': 42,
    'stratified': True
}

with open(SPLITS_PATH / 'summary.json', 'w') as f:
    json.dump(summary, f, indent=2)

print(f"âœ… RÃ©sumÃ© sauvegardÃ©: {SPLITS_PATH / 'summary.json'}")

# ============================================================================
# 5. VISUALISATION DES SPLITS
# ============================================================================
print("\n" + "=" * 70)
print("ğŸ“Š 5. Visualisation des splits")
print("=" * 70)

import matplotlib.pyplot as plt
import seaborn as sns

# PrÃ©parer les donnÃ©es pour le graphique
split_data = []
for genre in GENRES:
    split_data.append({
        'Genre': genre,
        'Split': 'Train',
        'Count': sum(train_labels == genre)
    })
    split_data.append({
        'Genre': genre,
        'Split': 'Val',
        'Count': sum(val_labels == genre)
    })
    split_data.append({
        'Genre': genre,
        'Split': 'Test',
        'Count': sum(test_labels == genre)
    })

plot_df = pd.DataFrame(split_data)

# CrÃ©er la figure
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Graphique 1 : Barplot groupÃ©
sns.barplot(data=plot_df, x='Genre', y='Count', hue='Split', ax=axes[0], palette='Set2')
axes[0].set_title('Distribution des fichiers par genre et split', fontsize=14, fontweight='bold')
axes[0].set_xlabel('Genre', fontsize=12)
axes[0].set_ylabel('Nombre de fichiers', fontsize=12)
axes[0].legend(title='Split')
axes[0].tick_params(axis='x', rotation=45)

# Graphique 2 : Pie chart des proportions globales
split_sizes = [len(train_files), len(val_files), len(test_files)]
split_labels = [f'Train\n({len(train_files)} fichiers)', 
                f'Val\n({len(val_files)} fichiers)', 
                f'Test\n({len(test_files)} fichiers)']
colors = sns.color_palette('Set2', 3)

axes[1].pie(split_sizes, labels=split_labels, autopct='%1.1f%%', 
            startangle=90, colors=colors, textprops={'fontsize': 11})
axes[1].set_title('Proportion globale des splits', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.savefig('results/figures/03_train_val_test_splits.png', dpi=300, bbox_inches='tight')
print("âœ… Visualisation sauvegardÃ©e: results/figures/03_train_val_test_splits.png")
plt.show()

# ============================================================================
# 6. VÃ‰RIFICATION FINALE
# ============================================================================
print("\n" + "=" * 70)
print("ğŸ” 6. VÃ©rification finale")
print("=" * 70)

# VÃ©rifier qu'il n'y a pas de fuites entre les splits
train_set = set(train_files)
val_set = set(val_files)
test_set = set(test_files)

leakage_train_val = train_set & val_set
leakage_train_test = train_set & test_set
leakage_val_test = val_set & test_set

if not (leakage_train_val or leakage_train_test or leakage_val_test):
    print("âœ… Aucune fuite de donnÃ©es dÃ©tectÃ©e entre les splits")
else:
    print("âŒ ATTENTION: Fuite de donnÃ©es dÃ©tectÃ©e!")
    if leakage_train_val:
        print(f"   Train âˆ© Val: {len(leakage_train_val)} fichiers")
    if leakage_train_test:
        print(f"   Train âˆ© Test: {len(leakage_train_test)} fichiers")
    if leakage_val_test:
        print(f"   Val âˆ© Test: {len(leakage_val_test)} fichiers")

# VÃ©rifier que tous les fichiers sont prÃ©sents
all_files = train_set | val_set | test_set
if len(all_files) == len(df):
    print(f"âœ… Tous les {len(df)} fichiers sont prÃ©sents dans les splits")
else:
    print(f"âŒ IncohÃ©rence: {len(all_files)} fichiers dans splits vs {len(df)} dans dataset")

# ============================================================================
# RAPPORT FINAL
# ============================================================================
print("\n" + "=" * 70)
print("âœ¨ RAPPORT FINAL")
print("=" * 70)

print(f"""
âœ… Splits Train/Val/Test crÃ©Ã©s avec succÃ¨s!

ğŸ“Š Configuration:
   - StratÃ©gie: Split stratifiÃ© par genre
   - Proportions: 70% / 15% / 15%
   - Random seed: 42 (reproductible)
   
ğŸ“š Statistiques:
   - Train: {len(train_files)} fichiers ({len(train_files)/len(df)*100:.1f}%)
   - Val:   {len(val_files)} fichiers ({len(val_files)/len(df)*100:.1f}%)
   - Test:  {len(test_files)} fichiers ({len(test_files)/len(df)*100:.1f}%)
   
ğŸ’¾ Fichiers gÃ©nÃ©rÃ©s:
   - data/splits/train.csv
   - data/splits/val.csv
   - data/splits/test.csv
   - data/splits/splits.json
   - data/splits/summary.json
   - results/figures/03_train_val_test_splits.png
   
ğŸ¯ Prochaines Ã©tapes:
   1. âœ… Exploration terminÃ©e
   2. âœ… Splits crÃ©Ã©s
   3. ğŸ”„ Prochaine Ã©tape: Rechercher baseline Kaggle
   4. â³ Ensuite: ImplÃ©menter le baseline
   5. â³ Puis: Fine-tuning WAV2VEC
""")

print("=" * 70)
print("ğŸ‰ PrÃ©paration des donnÃ©es terminÃ©e!")
print("=" * 70)